(set-info :smt-lib-version 2.6)
(set-logic BV)
(set-info :source |
   Scholl, Christoph; Disch, Stefan; Pigorsch, Florian and Kupferschmid, 
   Stefan; Using an SMT Solver and Craig Interpolation to Detect and Remove 
   Redundant Linear Constraints in Representations of Non-Convex Polyhedra.
   Proceedings of 6th International Workshop on Satisfiability Modulo
   Theories, Princeton, USA, July 2008.
   <http://abs.informatik.uni-freiburg.de/smtbench/>

Translated to BV by Mathias Preiner.
|)
(set-info :license "https://creativecommons.org/licenses/by/4.0/")
(set-info :category "random")
(set-info :status unknown)
(declare-fun y3 () (_ BitVec 32))
(declare-fun y5 () (_ BitVec 32))
(declare-fun y6 () (_ BitVec 32))
(declare-fun x1 () (_ BitVec 32))
(declare-fun y2 () (_ BitVec 32))
(declare-fun y4 () (_ BitVec 32))
(assert (exists ((?y2 (_ BitVec 32))) (or (or (or (and (or (exists ((?y4 (_ BitVec 32))) (or (or (exists ((?y5 (_ BitVec 32))) (and (forall ((?y6 (_ BitVec 32))) (bvsgt x1 (_ bv0 32))) (and (bvslt (bvadd (bvmul (_ bv96 32) ?y4) (bvmul (bvneg (_ bv6 32)) ?y2)) (_ bv0 32)) (not (= (bvadd (bvmul (_ bv34 32) ?y5) (bvmul (bvneg (_ bv46 32)) ?y4)) (bvneg (_ bv42 32))))))) (or (exists ((?y5 (_ BitVec 32))) (forall ((?y6 (_ BitVec 32))) (not (= (bvadd (bvadd (bvmul (_ bv22 32) ?y6) (bvmul (_ bv49 32) ?y4)) (bvmul (bvneg (_ bv51 32)) x1)) (bvneg (_ bv75 32)))))) (exists ((?y5 (_ BitVec 32))) (exists ((?y6 (_ BitVec 32))) (= (bvadd ?y5 ?y2) (bvneg (_ bv79 32))))))) (and (or (bvsgt (bvmul (bvneg (_ bv26 32)) ?y4) (_ bv66 32)) (= (bvadd (bvmul (bvneg (_ bv23 32)) ?y2) (bvmul (_ bv56 32) x1)) (_ bv0 32))) (bvsle (bvadd (bvmul (_ bv30 32) ?y4) (bvmul (_ bv40 32) x1)) (bvneg (_ bv34 32)))))) (or (and (exists ((?y4 (_ BitVec 32))) (or (bvslt (bvadd (bvmul (_ bv78 32) ?y2) (bvmul (bvneg (_ bv39 32)) x1)) (_ bv0 32)) (and (bvslt (bvadd (bvadd (bvmul (_ bv43 32) ?y4) (bvmul (_ bv69 32) ?y2)) (bvmul (_ bv98 32) x1)) (bvneg (_ bv8 32))) (forall ((?y5 (_ BitVec 32))) (= (bvadd (bvadd (bvmul (bvneg (_ bv22 32)) ?y5) (bvmul (bvneg (_ bv20 32)) ?y2)) (bvmul (_ bv6 32) x1)) (_ bv8 32)))))) (exists ((?y3 (_ BitVec 32))) (and (or (and (not (= (bvmul (bvneg (_ bv44 32)) x1) (_ bv0 32))) (bvsge (bvadd (bvmul (bvneg (_ bv90 32)) ?y2) (bvmul (bvneg (_ bv65 32)) x1)) (_ bv88 32))) (and (bvsge (bvadd (bvadd (bvmul (bvneg (_ bv71 32)) ?y3) (bvmul (bvneg (_ bv44 32)) ?y2)) (bvmul (_ bv58 32) x1)) (bvneg (_ bv17 32))) (bvsge (bvadd (bvmul (_ bv15 32) ?y2) (bvmul (bvneg (_ bv3 32)) x1)) (_ bv49 32)))) (or (bvslt (bvadd (bvmul (_ bv23 32) ?y3) (bvmul (_ bv80 32) ?y2)) (bvneg (_ bv44 32))) (exists ((?y5 (_ BitVec 32))) (bvsge (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv46 32)) ?y5) (bvmul (_ bv78 32) ?y3)) (bvmul (bvneg (_ bv51 32)) ?y2)) (bvmul (bvneg (_ bv33 32)) x1)) (_ bv34 32))))))) (forall ((?y5 (_ BitVec 32))) (or (or (and (bvslt (bvadd (bvmul (_ bv55 32) ?y2) (bvmul (bvneg (_ bv50 32)) x1)) (_ bv46 32)) (bvsle (bvadd (bvmul (bvneg (_ bv78 32)) ?y5) (bvmul (_ bv36 32) x1)) (bvneg (_ bv93 32)))) (and (bvsgt (bvadd (bvadd (bvmul (_ bv4 32) ?y5) (bvmul (bvneg (_ bv55 32)) ?y2)) (bvmul (bvneg (_ bv54 32)) x1)) (_ bv74 32)) (bvsge (bvadd (bvadd (bvmul (_ bv43 32) ?y5) (bvmul (bvneg (_ bv36 32)) ?y2)) (bvmul (_ bv94 32) x1)) (_ bv0 32)))) (or (exists ((?y6 (_ BitVec 32))) (bvsge (bvadd (bvadd (bvmul (_ bv3 32) ?y5) (bvmul (_ bv100 32) ?y2)) (bvmul (_ bv32 32) x1)) (bvneg (_ bv38 32)))) (exists ((?y6 (_ BitVec 32))) (bvslt (bvadd ?y2 (bvmul (_ bv65 32) x1)) (bvneg (_ bv8 32))))))))) (and (exists ((?y4 (_ BitVec 32))) (forall ((?y6 (_ BitVec 32))) (bvslt (bvmul (_ bv81 32) ?y6) (bvneg (_ bv2 32))))) (forall ((?y5 (_ BitVec 32))) (and (or (forall ((?y6 (_ BitVec 32))) (or (= (bvadd ?y5 (bvmul (_ bv98 32) x1)) (bvneg (_ bv90 32))) (bvslt (bvmul (bvneg (_ bv57 32)) ?y5) (bvneg (_ bv2 32))))) (exists ((?y6 (_ BitVec 32))) (and (bvslt (bvadd (bvadd (bvmul (_ bv15 32) ?y5) (bvmul (_ bv24 32) ?y2)) (bvmul (_ bv99 32) x1)) (_ bv97 32)) (bvsle (bvadd (bvadd (bvadd (bvmul (_ bv32 32) ?y6) (bvmul (_ bv87 32) ?y5)) (bvmul (_ bv64 32) ?y2)) (bvmul (bvneg (_ bv14 32)) x1)) (_ bv0 32))))) (and (and (bvslt (bvadd (bvmul (bvneg (_ bv60 32)) ?y5) (bvmul (bvneg (_ bv38 32)) x1)) (bvneg (_ bv8 32))) (bvsgt (bvmul (bvneg (_ bv44 32)) ?y2) (bvneg (_ bv66 32)))) (and (bvsge (bvadd (bvadd (bvmul (_ bv82 32) ?y5) (bvmul (_ bv27 32) ?y2)) (bvmul (bvneg (_ bv40 32)) x1)) (bvneg (_ bv23 32))) (not (= (bvmul (bvneg (_ bv35 32)) ?y2) (bvneg (_ bv18 32)))))))))) (exists ((?y3 (_ BitVec 32))) (forall ((?y4 (_ BitVec 32))) (and (bvsle (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv1 32)) ?y4) (bvmul (_ bv71 32) ?y3)) (bvmul (_ bv28 32) ?y2)) (bvmul (_ bv67 32) x1)) (bvneg (_ bv49 32))) (or (bvslt (bvadd ?y2 (bvmul (_ bv91 32) x1)) (_ bv0 32)) (and (bvsge (bvadd (bvmul (bvneg (_ bv100 32)) ?y4) (bvmul (_ bv19 32) ?y2)) (bvneg (_ bv23 32))) (and (bvslt (bvadd ?y2 x1) (_ bv0 32)) (= (bvadd (bvmul (bvneg (_ bv74 32)) ?y4) (bvmul (_ bv35 32) x1)) (_ bv44 32))))))))) (exists ((?y3 (_ BitVec 32))) (or (forall ((?y5 (_ BitVec 32))) (let ((?v_191 (bvmul (bvneg (_ bv89 32)) x1))) (and (forall ((?y6 (_ BitVec 32))) (let ((?v_192 (bvmul (_ bv20 32) ?y3))) (and (and (and (and (not (= (bvadd (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv65 32)) ?y6) (bvmul (bvneg (_ bv93 32)) ?y5)) (bvmul (_ bv10 32) ?y3)) (bvmul (bvneg (_ bv51 32)) ?y2)) (bvmul (_ bv2 32) x1)) (_ bv69 32))) (bvsge (bvadd (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv63 32)) ?y6) (bvmul (_ bv96 32) ?y5)) (bvmul (_ bv63 32) ?y3)) (bvmul (_ bv90 32) ?y2)) (bvmul (bvneg (_ bv38 32)) x1)) (_ bv73 32))) (or (bvsge (bvadd (bvadd (bvmul (bvneg (_ bv26 32)) ?y5) (bvmul (_ bv32 32) ?y3)) (bvmul (bvneg (_ bv17 32)) ?y2)) (_ bv34 32)) (bvsle (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv96 32)) ?y6) (bvmul (bvneg (_ bv54 32)) ?y5)) ?v_192) (bvmul (bvneg (_ bv23 32)) ?y2)) (bvneg (_ bv46 32))))) (and (or (bvsgt (bvadd (bvadd (bvadd (bvadd (bvmul (_ bv75 32) ?y6) (bvmul (bvneg (_ bv69 32)) ?y5)) (bvmul (_ bv25 32) ?y3)) (bvmul (_ bv4 32) ?y2)) (bvmul (bvneg (_ bv6 32)) x1)) (_ bv0 32)) (bvslt (bvadd (bvmul (_ bv82 32) ?y3) (bvmul (bvneg (_ bv31 32)) x1)) (_ bv0 32))) (or (bvsge (bvadd (bvadd (bvmul (bvneg (_ bv13 32)) ?y5) ?v_192) (bvmul (bvneg (_ bv29 32)) x1)) (bvneg (_ bv5 32))) (= (bvadd (bvadd (bvmul (bvneg (_ bv47 32)) ?y6) (bvmul (bvneg (_ bv59 32)) ?y2)) (bvmul (bvneg (_ bv13 32)) x1)) (bvneg (_ bv91 32)))))) (and (or (or (= (bvadd (bvadd (bvmul (bvneg (_ bv49 32)) ?y6) (bvmul (_ bv55 32) ?y5)) (bvmul (bvneg (_ bv67 32)) ?y2)) (_ bv0 32)) (bvsle (bvadd (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv74 32)) ?y6) (bvmul (bvneg (_ bv76 32)) ?y5)) (bvmul (bvneg (_ bv2 32)) ?y3)) (bvmul (_ bv44 32) ?y2)) (bvmul (bvneg (_ bv69 32)) x1)) (_ bv53 32))) (and (= (bvadd (bvadd (bvadd (bvmul (_ bv11 32) ?y6) (bvmul (_ bv51 32) ?y5)) (bvmul (bvneg (_ bv32 32)) ?y3)) (bvmul (_ bv19 32) ?y2)) (_ bv98 32)) (bvsgt (bvadd (bvadd (bvadd (bvadd (bvmul (_ bv71 32) ?y6) (bvmul (_ bv72 32) ?y5)) (bvmul (_ bv56 32) ?y3)) (bvmul (_ bv11 32) ?y2)) (bvmul (bvneg (_ bv66 32)) x1)) (_ bv0 32)))) (= (bvadd (bvadd (bvmul (_ bv53 32) ?y5) (bvmul (bvneg (_ bv85 32)) ?y2)) (bvmul (bvneg (_ bv78 32)) x1)) (_ bv0 32)))))) (or (and (or (= (bvadd (bvadd (bvmul (bvneg (_ bv25 32)) ?y5) (bvmul (bvneg (_ bv77 32)) ?y3)) ?v_191) (_ bv71 32)) (or (bvsge (bvadd (bvadd (bvmul (bvneg (_ bv97 32)) ?y5) (bvmul (_ bv31 32) ?y2)) (bvmul (bvneg (_ bv72 32)) x1)) (bvneg (_ bv26 32))) (= (bvadd (bvmul (_ bv48 32) ?y3) (bvmul (bvneg (_ bv91 32)) ?y2)) (bvneg (_ bv21 32))))) (and (and (not (= (bvadd (bvmul (bvneg (_ bv90 32)) ?y5) (bvmul (bvneg (_ bv37 32)) ?y2)) (_ bv0 32))) (bvslt (bvadd (bvadd (bvmul (_ bv44 32) ?y5) (bvmul (bvneg (_ bv65 32)) ?y2)) ?v_191) (bvneg (_ bv44 32)))) (bvsle (bvadd (bvadd (bvadd (bvmul (_ bv93 32) ?y5) (bvmul (_ bv60 32) ?y3)) (bvmul (_ bv10 32) ?y2)) (bvmul (bvneg (_ bv41 32)) x1)) (_ bv80 32)))) (or (and (not (= (bvadd (bvmul (bvneg (_ bv10 32)) ?y5) (bvmul (bvneg (_ bv98 32)) ?y3)) (_ bv0 32))) (bvsge (bvadd (bvmul (_ bv68 32) ?y2) (bvmul (_ bv97 32) x1)) (_ bv40 32))) (or (not (= (bvadd (bvadd (bvmul (_ bv85 32) ?y5) (bvmul (bvneg (_ bv4 32)) ?y2)) (bvmul (_ bv42 32) x1)) (_ bv96 32))) (bvslt (bvadd (bvadd (bvmul (bvneg (_ bv69 32)) ?y5) (bvmul (bvneg (_ bv5 32)) ?y2)) (bvmul (bvneg (_ bv61 32)) x1)) (_ bv19 32)))))))) (and (exists ((?y4 (_ BitVec 32))) (or (forall ((?y5 (_ BitVec 32))) (forall ((?y6 (_ BitVec 32))) (or (and (bvsge (bvadd (bvadd (bvadd (bvadd (bvmul (_ bv64 32) ?y6) (bvmul (bvneg (_ bv6 32)) ?y5)) (bvmul (bvneg (_ bv78 32)) ?y4)) (bvmul (bvneg (_ bv14 32)) ?y2)) (bvmul (_ bv11 32) x1)) (bvneg (_ bv8 32))) (= (bvadd (bvmul (_ bv94 32) ?y6) (bvmul (bvneg (_ bv23 32)) ?y3)) (_ bv92 32))) (and (bvsge (bvadd (bvadd (bvadd (bvadd (bvmul (_ bv2 32) ?y6) (bvmul (_ bv83 32) ?y5)) (bvmul (_ bv71 32) ?y4)) (bvmul (bvneg (_ bv42 32)) ?y2)) (bvmul (bvneg (_ bv50 32)) x1)) (bvneg (_ bv68 32))) (bvsle (bvadd (bvadd (bvadd (bvadd (bvmul (_ bv11 32) ?y6) (bvmul (_ bv54 32) ?y5)) (bvmul (_ bv42 32) ?y3)) (bvmul (bvneg (_ bv64 32)) ?y2)) (bvmul (_ bv62 32) x1)) (_ bv59 32)))))) (or (forall ((?y6 (_ BitVec 32))) (and (or (bvsge (bvadd (bvadd (bvmul (_ bv49 32) ?y6) (bvmul (bvneg (_ bv96 32)) ?y2)) (bvmul (_ bv76 32) x1)) (bvneg (_ bv8 32))) (bvsge (bvadd (bvadd (bvmul (bvneg (_ bv66 32)) ?y6) (bvmul (bvneg (_ bv78 32)) ?y3)) (bvmul (bvneg (_ bv13 32)) ?y2)) (_ bv94 32))) (bvslt (bvadd (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv60 32)) ?y6) (bvmul (_ bv67 32) ?y4)) (bvmul (_ bv100 32) ?y3)) (bvmul (bvneg (_ bv45 32)) ?y2)) (bvmul (bvneg (_ bv32 32)) x1)) (_ bv19 32)))) (or (exists ((?y6 (_ BitVec 32))) (or (not (= (bvadd (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv42 32)) ?y6) (bvmul (bvneg (_ bv70 32)) ?y4)) (bvmul (_ bv71 32) ?y3)) (bvmul (bvneg (_ bv71 32)) ?y2)) (bvmul (_ bv56 32) x1)) (bvneg (_ bv60 32)))) (bvsge (bvmul (_ bv7 32) x1) (_ bv97 32)))) (and (= (bvadd (bvadd (bvmul (_ bv78 32) ?y4) (bvmul (_ bv52 32) ?y3)) (bvmul (_ bv25 32) x1)) (bvneg (_ bv48 32))) (bvsle (bvadd (bvadd (bvmul (_ bv36 32) ?y4) (bvmul (bvneg (_ bv33 32)) ?y2)) (bvmul (_ bv87 32) x1)) (_ bv0 32))))))) (forall ((?y4 (_ BitVec 32))) (forall ((?y5 (_ BitVec 32))) (or (and (and (or (bvsle (bvadd (bvadd (bvmul (_ bv41 32) ?y5) (bvmul (_ bv41 32) ?y4)) (bvmul (bvneg (_ bv30 32)) x1)) (_ bv89 32)) (bvsgt (bvadd (bvadd (bvmul (_ bv87 32) ?y5) (bvmul (bvneg (_ bv66 32)) ?y4)) (bvmul (_ bv2 32) x1)) (_ bv63 32))) (and (bvsle (bvadd (bvadd (bvmul (_ bv6 32) ?y5) (bvmul (bvneg (_ bv100 32)) ?y4)) (bvmul (_ bv30 32) x1)) (bvneg (_ bv52 32))) (bvsge (bvadd (bvadd (bvmul (bvneg (_ bv65 32)) ?y4) (bvmul (_ bv42 32) ?y2)) (bvmul (_ bv89 32) x1)) (_ bv100 32)))) (or (bvsle (bvadd (bvadd (bvmul (bvneg (_ bv31 32)) ?y5) (bvmul (_ bv79 32) ?y4)) (bvmul (bvneg (_ bv3 32)) x1)) (_ bv0 32)) (or (bvsge (bvadd (bvadd (bvmul (bvneg (_ bv87 32)) ?y3) (bvmul (bvneg (_ bv1 32)) ?y2)) (bvmul (bvneg (_ bv55 32)) x1)) (_ bv82 32)) (not (= (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv50 32)) ?y5) (bvmul (bvneg (_ bv38 32)) ?y3)) (bvmul (bvneg (_ bv31 32)) ?y2)) (bvmul (bvneg (_ bv10 32)) x1)) (_ bv3 32)))))) (and (forall ((?y6 (_ BitVec 32))) (and (or (not (= (bvadd (bvadd (bvmul (bvneg (_ bv8 32)) ?y6) (bvmul (bvneg (_ bv79 32)) ?y5)) (bvmul (bvneg (_ bv19 32)) x1)) (_ bv86 32))) (= (bvadd (bvadd (bvadd (bvadd (bvmul (_ bv87 32) ?y6) (bvmul (bvneg (_ bv84 32)) ?y4)) (bvmul (_ bv32 32) ?y3)) (bvmul (bvneg (_ bv30 32)) ?y2)) (bvmul (_ bv59 32) x1)) (bvneg (_ bv60 32)))) (or (bvslt (bvadd (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv56 32)) ?y6) (bvmul (_ bv36 32) ?y5)) (bvmul (_ bv40 32) ?y4)) (bvmul (_ bv11 32) ?y3)) (bvmul (bvneg (_ bv64 32)) ?y2)) (_ bv52 32)) (bvsle (bvadd (bvadd (bvmul (bvneg (_ bv16 32)) ?y6) (bvmul (_ bv92 32) ?y2)) (bvmul (_ bv1 32) x1)) (_ bv0 32))))) (forall ((?y6 (_ BitVec 32))) (and (and (= (bvadd (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv57 32)) ?y5) (bvmul (bvneg (_ bv41 32)) ?y4)) (bvmul (_ bv31 32) ?y3)) (bvmul (_ bv6 32) ?y2)) (bvmul (_ bv99 32) x1)) (_ bv90 32)) (= (bvadd (bvadd (bvadd (bvadd (bvmul (_ bv19 32) ?y6) (bvmul (_ bv80 32) ?y5)) (bvmul (_ bv74 32) ?y4)) (bvmul (bvneg (_ bv94 32)) ?y3)) (bvmul (_ bv78 32) x1)) (bvneg (_ bv18 32)))) (and (not (= (bvadd (bvadd (bvmul (bvneg (_ bv2 32)) ?y5) (bvmul (bvneg (_ bv80 32)) ?y3)) (bvmul (bvneg (_ bv9 32)) x1)) (_ bv0 32))) (= (bvadd (bvadd (bvadd (bvadd (bvmul (bvneg (_ bv99 32)) ?y6) (bvmul (_ bv51 32) ?y5)) (bvmul (bvneg (_ bv44 32)) ?y4)) (bvmul (bvneg (_ bv61 32)) ?y2)) (bvmul (_ bv70 32) x1)) (bvneg (_ bv15 32)))))))))))))) false)))
(check-sat)
(exit)
